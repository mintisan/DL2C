#!/usr/bin/env python3
"""
ä¸‰ç§è¯­è¨€ä½¿ç”¨å…±åŒæ•°æ®çš„æ¨ç†æ€§èƒ½å’Œå‡†ç¡®æ€§å¯¹æ¯”åˆ†æè„šæœ¬
å¯¹æ¯”Pythonã€C++ã€Cè¯­è¨€åœ¨ç›¸åŒè¾“å…¥æ•°æ®ä¸‹çš„æ€§èƒ½å’Œå‡†ç¡®æ€§
"""

import json
import os
import sys
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np

class CommonDataPerformanceComparator:
    def __init__(self, results_dir="./results"):
        self.results_dir = Path(results_dir)
        self.python_data = None
        self.cpp_data = None
        self.c_data = None
        
    def load_results(self):
        """åŠ è½½ä¸‰ç§è¯­è¨€çš„å…±åŒæ•°æ®æ¨ç†ç»“æœ"""
        print("ğŸ” åŠ è½½å…±åŒæ•°æ®æ¨ç†ç»“æœæ–‡ä»¶...")
        
        # Pythonç»“æœ
        python_path = self.results_dir / "python_inference_common_results.json"
        if python_path.exists():
            with open(python_path, 'r', encoding='utf-8') as f:
                self.python_data = json.load(f)
            print(f"âœ“ Pythonç»“æœ: {python_path}")
        else:
            print(f"âœ— Pythonç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {python_path}")
            
        # C++ç»“æœ
        cpp_path = self.results_dir / "cpp_inference_common_results.json"
        if cpp_path.exists():
            with open(cpp_path, 'r') as f:
                self.cpp_data = json.load(f)
            print(f"âœ“ C++ç»“æœ: {cpp_path}")
        else:
            print(f"âœ— C++ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {cpp_path}")
            
        # Cç»“æœ
        c_path = self.results_dir / "c_inference_common_results.json"
        if c_path.exists():
            with open(c_path, 'r') as f:
                self.c_data = json.load(f)
            print(f"âœ“ Cç»“æœ: {c_path}")
        else:
            print(f"âœ— Cç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {c_path}")
            
    def analyze_accuracy_consistency(self):
        """åˆ†æå‡†ç¡®æ€§å’Œç»“æœä¸€è‡´æ€§"""
        print("\nğŸ“Š å‡†ç¡®æ€§å’Œç»“æœä¸€è‡´æ€§åˆ†æ")
        print("=" * 80)
        
        if not any([self.python_data, self.cpp_data, self.c_data]):
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶")
            return
            
        # åŸºç¡€å‡†ç¡®æ€§è¡¨æ ¼
        print("\nğŸ¯ å‡†ç¡®æ€§å¯¹æ¯”:")
        print("-" * 60)
        print(f"{'è¯­è¨€':<10} {'å‡†ç¡®ç‡':<8} {'æ­£ç¡®æ•°/æ€»æ•°':<12} {'FPS':<8}")
        print("-" * 60)
        
        accuracies = {}
        
        for name, data in [("Python", self.python_data), ("C++", self.cpp_data), ("C", self.c_data)]:
            if data and 'summary' in data:
                summary = data['summary']
                accuracy = summary.get('accuracy', 0) * 100
                correct = summary.get('correct_predictions', 0)
                total = summary.get('total_samples', 0)
                fps = summary.get('fps', 0)
                
                print(f"{name:<10} {accuracy:<7.1f}% {correct}/{total:<9} {fps:<7.1f}")
                accuracies[name] = accuracy
                
        # ç»“æœä¸€è‡´æ€§åˆ†æ
        self.analyze_prediction_consistency()
        
    def analyze_prediction_consistency(self):
        """åˆ†æé¢„æµ‹ç»“æœçš„ä¸€è‡´æ€§"""
        print(f"\nğŸ” é€æ ·æœ¬é¢„æµ‹å¯¹æ¯”:")
        print("-" * 80)
        
        # è·å–æ‰€æœ‰ç»“æœæ•°æ®
        all_results = {}
        for name, data in [("Python", self.python_data), ("C++", self.cpp_data), ("C", self.c_data)]:
            if data and 'results' in data:
                all_results[name] = {r['sample_id']: r for r in data['results']}
        
        if len(all_results) < 2:
            print("âš ï¸  ç»“æœæ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ")
            return
            
        # æ‰¾å‡ºå…±åŒçš„æ ·æœ¬ID
        sample_ids = None
        for results in all_results.values():
            if sample_ids is None:
                sample_ids = set(results.keys())
            else:
                sample_ids = sample_ids.intersection(set(results.keys()))
        
        sample_ids = sorted(list(sample_ids))
        
        print(f"æ ·æœ¬ID | çœŸå®æ ‡ç­¾ | {'Python':<8} | {'C++':<8} | {'C':<8} | ä¸€è‡´æ€§")
        print("-" * 60)
        
        consistency_count = 0
        total_samples = len(sample_ids)
        
        for sample_id in sample_ids:
            true_label = None
            predictions = {}
            confidences = {}
            
            for lang in all_results:
                if sample_id in all_results[lang]:
                    result = all_results[lang][sample_id]
                    predictions[lang] = result['predicted_class']
                    confidences[lang] = result['confidence']
                    if true_label is None:
                        true_label = result['true_label']
            
            # æ£€æŸ¥ä¸€è‡´æ€§
            pred_values = list(predictions.values())
            is_consistent = len(set(pred_values)) == 1 if pred_values else False
            if is_consistent:
                consistency_count += 1
                
            # æ˜¾ç¤ºç»“æœ
            python_pred = f"{predictions.get('Python', 'N/A')}"
            cpp_pred = f"{predictions.get('C++', 'N/A')}"
            c_pred = f"{predictions.get('C', 'N/A')}"
            consistency_mark = "âœ“" if is_consistent else "âœ—"
            
            print(f"{sample_id:6d} | {true_label:8d} | {python_pred:<8} | {cpp_pred:<8} | {c_pred:<8} | {consistency_mark}")
        
        consistency_rate = consistency_count / total_samples * 100
        print(f"\nğŸ¯ é¢„æµ‹ä¸€è‡´æ€§: {consistency_count}/{total_samples} ({consistency_rate:.1f}%)")
        
        if consistency_rate < 100:
            print("âš ï¸  å­˜åœ¨é¢„æµ‹ä¸ä¸€è‡´çš„æƒ…å†µï¼Œå¯èƒ½åŸå› :")
            print("   - æ•°å€¼ç²¾åº¦å·®å¼‚")
            print("   - é¢„å¤„ç†æˆ–åå¤„ç†å®ç°å·®å¼‚")
            print("   - éšæœºæ€§æˆ–å¹¶è¡Œè®¡ç®—å·®å¼‚")
            
    def analyze_performance(self):
        """åˆ†ææ€§èƒ½æ•°æ®"""
        print("\nğŸ“ˆ æ€§èƒ½åˆ†æ")
        print("=" * 80)
        
        # æ€§èƒ½ç»Ÿè®¡
        times = {}
        
        for name, data in [("Python", self.python_data), ("C++", self.cpp_data), ("C", self.c_data)]:
            if data and 'summary' in data:
                times[name] = data['summary']['average_inference_time_ms']
                
        if len(times) >= 2:
            print(f"\nâš¡ æ€§èƒ½æå‡åˆ†æ:")
            print("-" * 40)
            
            if 'Python' in times:
                baseline = times['Python']
                if 'C++' in times:
                    speedup = baseline / times['C++']
                    print(f"C++ vs Python:   {speedup:.2f}x åŠ é€Ÿ")
                    
                if 'C' in times:
                    speedup = baseline / times['C']
                    print(f"C vs Python:     {speedup:.2f}x åŠ é€Ÿ")
                    
            if 'C++' in times and 'C' in times:
                ratio = times['C++'] / times['C']
                if ratio > 1:
                    print(f"C vs C++:        {ratio:.2f}x åŠ é€Ÿ")
                else:
                    print(f"C++ vs C:        {1/ratio:.2f}x åŠ é€Ÿ")
        
        # è¯¦ç»†æ—¶é—´åˆ†æ
        self.detailed_timing_analysis()
        
    def detailed_timing_analysis(self):
        """è¯¦ç»†æ—¶é—´åˆ†æ"""
        print(f"\nâ±ï¸  è¯¦ç»†æ—¶é—´ç»Ÿè®¡:")
        print("-" * 50)
        
        for name, data in [("Python", self.python_data), ("C++", self.cpp_data), ("C", self.c_data)]:
            if data and 'results' in data:
                times = [r['inference_time_ms'] for r in data['results']]
                if times:
                    times_array = np.array(times)
                    print(f"\n{name} æ¨ç†æ—¶é—´ç»Ÿè®¡:")
                    print(f"  å¹³å‡æ—¶é—´: {np.mean(times_array):.3f} ms")
                    print(f"  æ ‡å‡†å·®:   {np.std(times_array):.3f} ms")
                    print(f"  æœ€å°æ—¶é—´: {np.min(times_array):.3f} ms")
                    print(f"  æœ€å¤§æ—¶é—´: {np.max(times_array):.3f} ms")
                    print(f"  ä¸­ä½æ•°:   {np.median(times_array):.3f} ms")
                    
    def generate_detailed_visualization(self):
        """ç”Ÿæˆè¯¦ç»†çš„å¯è§†åŒ–å›¾è¡¨"""
        try:
            print(f"\nğŸ“Š ç”Ÿæˆè¯¦ç»†å¯¹æ¯”å›¾è¡¨...")
            
            # å‡†å¤‡æ•°æ®
            languages = []
            accuracies = []
            avg_times = []
            fps_values = []
            
            for name, data in [("Python", self.python_data), ("C++", self.cpp_data), ("C", self.c_data)]:
                if data and 'summary' in data:
                    languages.append(name)
                    accuracies.append(data['summary'].get('accuracy', 0) * 100)
                    avg_times.append(data['summary']['average_inference_time_ms'])
                    fps_values.append(data['summary']['fps'])
                    
            if len(languages) < 2:
                print("âš ï¸  æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
                return
                
            # åˆ›å»ºå­å›¾
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
            
            colors = ['#3498db', '#e74c3c', '#2ecc71'][:len(languages)]
            
            # 1. å‡†ç¡®ç‡å¯¹æ¯”
            bars1 = ax1.bar(languages, accuracies, color=colors, alpha=0.8)
            ax1.set_ylabel('Accuracy (%)')
            ax1.set_title('Accuracy Comparison')
            ax1.set_ylim(0, 100)
            for bar, acc in zip(bars1, accuracies):
                height = bar.get_height()
                ax1.annotate(f'{acc:.1f}%',
                           xy=(bar.get_x() + bar.get_width() / 2, height),
                           xytext=(0, 3),
                           textcoords="offset points",
                           ha='center', va='bottom')
            
            # 2. æ¨ç†æ—¶é—´å¯¹æ¯”
            bars2 = ax2.bar(languages, avg_times, color=colors, alpha=0.8)
            ax2.set_ylabel('Inference Time (ms)')
            ax2.set_title('Average Inference Time Comparison')
            for bar, time in zip(bars2, avg_times):
                height = bar.get_height()
                ax2.annotate(f'{time:.2f}ms',
                           xy=(bar.get_x() + bar.get_width() / 2, height),
                           xytext=(0, 3),
                           textcoords="offset points",
                           ha='center', va='bottom')
            
            # 3. FPSå¯¹æ¯”
            bars3 = ax3.bar(languages, fps_values, color=colors, alpha=0.8)
            ax3.set_ylabel('Inference Speed (FPS)')
            ax3.set_title('Inference Speed Comparison')
            for bar, fps in zip(bars3, fps_values):
                height = bar.get_height()
                ax3.annotate(f'{fps:.1f}',
                           xy=(bar.get_x() + bar.get_width() / 2, height),
                           xytext=(0, 3),
                           textcoords="offset points",
                           ha='center', va='bottom')
            
            # 4. ç»¼åˆè¯„åˆ† (å‡†ç¡®ç‡ Ã— ç›¸å¯¹é€Ÿåº¦)
            if len(languages) > 1:
                baseline_time = max(avg_times)  # ä½¿ç”¨æœ€æ…¢çš„ä½œä¸ºåŸºå‡†
                speed_scores = [baseline_time / t for t in avg_times]
                combined_scores = [acc * speed / 100 for acc, speed in zip(accuracies, speed_scores)]
                
                bars4 = ax4.bar(languages, combined_scores, color=colors, alpha=0.8)
                ax4.set_ylabel('Combined Score (Accuracy Ã— Relative Speed)')
                ax4.set_title('Overall Performance Score')
                for bar, score in zip(bars4, combined_scores):
                    height = bar.get_height()
                    ax4.annotate(f'{score:.2f}',
                               xy=(bar.get_x() + bar.get_width() / 2, height),
                               xytext=(0, 3),
                               textcoords="offset points",
                               ha='center', va='bottom')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            chart_path = self.results_dir / "common_data_comparison.png"
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.show()
            
            print(f"âœ“ å›¾è¡¨å·²ä¿å­˜: {chart_path}")
            
        except ImportError:
            print("âš ï¸  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
        except Exception as e:
            print(f"âš ï¸  å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
            
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print(f"\nğŸ“ ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
        
        report_path = self.results_dir / "common_data_comparison_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# MNISTæ¨¡å‹ä¸‰ç§è¯­è¨€å…±åŒæ•°æ®æ¨ç†å¯¹æ¯”æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {self.get_timestamp()}\n\n")
            
            # æ¦‚è¦
            f.write("## æ¦‚è¦\n\n")
            f.write("æœ¬æŠ¥å‘Šå¯¹æ¯”äº†Pythonã€C++å’ŒCè¯­è¨€åœ¨ä½¿ç”¨å®Œå…¨ç›¸åŒçš„MNISTæµ‹è¯•æ•°æ®ä¸‹çš„æ¨ç†æ€§èƒ½å’Œå‡†ç¡®æ€§ã€‚\n")
            f.write("è¿™æ˜¯ä¸€ä¸ªå…¬å¹³çš„å¯¹æ¯”ï¼Œç¡®ä¿ä¸‰ç§è¯­è¨€å¤„ç†å®Œå…¨ç›¸åŒçš„è¾“å…¥æ•°æ®ã€‚\n\n")
            
            # æµ‹è¯•è®¾ç½®
            f.write("## æµ‹è¯•è®¾ç½®\n\n")
            f.write("- æµ‹è¯•æ•°æ®: 10ä¸ªçœŸå®çš„MNISTæ ·æœ¬ï¼ˆå›ºå®šç§å­é€‰æ‹©ï¼‰\n")
            f.write("- æ•°æ®æ ¼å¼: 28Ã—28åƒç´ ï¼Œfloat32æ ¼å¼\n")
            f.write("- é¢„å¤„ç†: ç»Ÿä¸€çš„æ ‡å‡†åŒ– (mean=0.1307, std=0.3081)\n")
            f.write("- æ¨¡å‹: ç›¸åŒçš„ONNXæ¨¡å‹æ–‡ä»¶\n")
            f.write("- è¿è¡Œç¯å¢ƒ: macOS, ONNX Runtime 1.16.0\n\n")
            
            # ç»“æœè¡¨æ ¼
            f.write("## æµ‹è¯•ç»“æœ\n\n")
            f.write("| è¯­è¨€ | å‡†ç¡®ç‡ | å¹³å‡æ¨ç†æ—¶é—´(ms) | FPS | æ­£ç¡®é¢„æµ‹æ•° |\n")
            f.write("|------|--------|------------------|-----|-------------|\n")
            
            for name, data in [("Python", self.python_data), ("C++", self.cpp_data), ("C", self.c_data)]:
                if data and 'summary' in data:
                    summary = data['summary']
                    accuracy = summary.get('accuracy', 0) * 100
                    avg_time = summary['average_inference_time_ms']
                    fps = summary['fps']
                    correct = summary.get('correct_predictions', 0)
                    total = summary.get('total_samples', 0)
                    
                    f.write(f"| {name} | {accuracy:.1f}% | {avg_time:.2f} | {fps:.1f} | {correct}/{total} |\n")
            
            # æ€§èƒ½åˆ†æ
            f.write("\n## æ€§èƒ½åˆ†æ\n\n")
            
            times = {}
            accuracies = {}
            for name, data in [("Python", self.python_data), ("C++", self.cpp_data), ("C", self.c_data)]:
                if data and 'summary' in data:
                    times[name] = data['summary']['average_inference_time_ms']
                    accuracies[name] = data['summary'].get('accuracy', 0) * 100
            
            if 'Python' in times:
                baseline = times['Python']
                f.write(f"### ç›¸å¯¹äºPythonçš„æ€§èƒ½æå‡\n\n")
                
                if 'C++' in times:
                    speedup = baseline / times['C++']
                    f.write(f"- **C++**: {speedup:.2f}x åŠ é€Ÿ\n")
                    
                if 'C' in times:
                    speedup = baseline / times['C']
                    f.write(f"- **Cè¯­è¨€**: {speedup:.2f}x åŠ é€Ÿ\n")
            
            # å‡†ç¡®æ€§åˆ†æ
            f.write(f"\n### å‡†ç¡®æ€§å¯¹æ¯”\n\n")
            if len(accuracies) > 1:
                max_acc = max(accuracies.values())
                min_acc = min(accuracies.values())
                acc_diff = max_acc - min_acc
                f.write(f"- æœ€é«˜å‡†ç¡®ç‡: {max_acc:.1f}%\n")
                f.write(f"- æœ€ä½å‡†ç¡®ç‡: {min_acc:.1f}%\n")
                f.write(f"- å‡†ç¡®ç‡å·®å¼‚: {acc_diff:.1f}%\n")
                
                if acc_diff < 1.0:
                    f.write("- **ç»“è®º**: ä¸‰ç§è¯­è¨€å®ç°çš„å‡†ç¡®æ€§åŸºæœ¬ä¸€è‡´\n")
                else:
                    f.write("- **æ³¨æ„**: å­˜åœ¨å‡†ç¡®æ€§å·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥å®ç°ç»†èŠ‚\n")
            
            # ç»“è®º
            f.write(f"\n## ç»“è®º\n\n")
            f.write("1. **å‡†ç¡®æ€§**: ä½¿ç”¨ç›¸åŒæ•°æ®ï¼Œä¸‰ç§è¯­è¨€çš„æ¨ç†å‡†ç¡®æ€§åº”è¯¥å®Œå…¨ä¸€è‡´\n")
            f.write("2. **æ€§èƒ½**: ç¼–è¯‘å‹è¯­è¨€(C/C++)æ˜¾è‘—ä¼˜äºè§£é‡Šå‹è¯­è¨€(Python)\n")
            f.write("3. **ä¸€è‡´æ€§**: éªŒè¯äº†ä¸‰ç§å®ç°çš„æ­£ç¡®æ€§\n")
            f.write("4. **é€‰æ‹©å»ºè®®**:\n")
            f.write("   - å¼€å‘é˜¶æ®µ: Python (å¿«é€ŸåŸå‹)\n")
            f.write("   - ç”Ÿäº§éƒ¨ç½²: C/C++ (é«˜æ€§èƒ½)\n")
            f.write("   - ç§»åŠ¨ç«¯: Cè¯­è¨€ (æœ€å°ä¾èµ–)\n\n")
            
        print(f"âœ“ ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
    def get_timestamp(self):
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
    def run_comparison(self):
        """è¿è¡Œå®Œæ•´çš„å¯¹æ¯”åˆ†æ"""
        print("ğŸ¯ ä¸‰ç§è¯­è¨€å…±åŒæ•°æ®æ¨ç†å¯¹æ¯”åˆ†æ")
        print("=" * 60)
        
        # åŠ è½½ç»“æœ
        self.load_results()
        
        if not any([self.python_data, self.cpp_data, self.c_data]):
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶")
            print("è¯·å…ˆè¿è¡Œç›¸åº”çš„æ¨ç†æµ‹è¯•:")
            print("  python inference/python_inference_common.py")
            print("  cd build/build_macos && ./bin/mnist_inference_cpp_common")
            print("  cd build/build_macos && ./bin/mnist_inference_c_common")
            return
        
        # åˆ†æå‡†ç¡®æ€§å’Œä¸€è‡´æ€§
        self.analyze_accuracy_consistency()
        
        # åˆ†ææ€§èƒ½
        self.analyze_performance()
        
        # ç”Ÿæˆå¯è§†åŒ–
        self.generate_detailed_visualization()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_comprehensive_report()
        
        print(f"\nğŸ‰ å…±åŒæ•°æ®å¯¹æ¯”åˆ†æå®Œæˆ!")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  - è¯¦ç»†å›¾è¡¨: {self.results_dir}/common_data_comparison.png")
        print(f"  - ç»¼åˆæŠ¥å‘Š: {self.results_dir}/common_data_comparison_report.md")

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥ç»“æœç›®å½•
    results_dir = "./results"
    if not os.path.exists(results_dir):
        print(f"âŒ ç»“æœç›®å½•ä¸å­˜åœ¨: {results_dir}")
        sys.exit(1)
        
    # è¿è¡Œå¯¹æ¯”åˆ†æ
    comparator = CommonDataPerformanceComparator(results_dir)
    comparator.run_comparison()

if __name__ == "__main__":
    main() 