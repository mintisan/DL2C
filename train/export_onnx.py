import torch
import torch.onnx
import onnx
import onnxruntime
import numpy as np
import os
from train_model import MNISTNet
import torchvision.transforms as transforms
import torchvision

def export_to_onnx():
    """å°†PyTorchæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼"""
    print("å¼€å§‹å¯¼å‡ºONNXæ¨¡å‹...")
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    print("åŠ è½½PyTorchæ¨¡å‹...")
    model = MNISTNet()
    model.load_state_dict(torch.load('../models/mnist_model.pth', map_location='cpu', weights_only=True))
    model.eval()
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥ï¼ˆMNISTå›¾åƒå¤§å°ä¸º28x28ï¼‰
    print("åˆ›å»ºç¤ºä¾‹è¾“å…¥...")
    dummy_input = torch.randn(1, 1, 28, 28)
    
    # å¯¼å‡ºONNXæ¨¡å‹
    onnx_path = '../models/mnist_model.onnx'
    print(f"å¯¼å‡ºONNXæ¨¡å‹åˆ°: {onnx_path}")
    
    torch.onnx.export(
        model,                          # è¦å¯¼å‡ºçš„æ¨¡å‹
        dummy_input,                    # ç¤ºä¾‹è¾“å…¥
        onnx_path,                      # è¾“å‡ºè·¯å¾„
        export_params=True,             # å¯¼å‡ºå‚æ•°
        opset_version=11,               # ONNXç®—å­é›†ç‰ˆæœ¬
        do_constant_folding=True,       # å¸¸é‡æŠ˜å ä¼˜åŒ–
        input_names=['input'],          # è¾“å…¥èŠ‚ç‚¹åç§°
        output_names=['output'],        # è¾“å‡ºèŠ‚ç‚¹åç§°
        dynamic_axes={                  # åŠ¨æ€ç»´åº¦ï¼ˆæ”¯æŒä¸åŒbatch sizeï¼‰
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    # éªŒè¯ONNXæ¨¡å‹
    print("éªŒè¯ONNXæ¨¡å‹...")
    try:
        onnx_model = onnx.load(onnx_path)
        onnx.checker.check_model(onnx_model)
        print("âœ“ ONNXæ¨¡å‹éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âœ— ONNXæ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return None
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print("\n=== ONNXæ¨¡å‹ä¿¡æ¯ ===")
    print(f"ONNXç‰ˆæœ¬: {onnx.version.version}")
    print(f"ç®—å­é›†ç‰ˆæœ¬: {onnx_model.opset_import[0].version}")
    print(f"è¾“å…¥èŠ‚ç‚¹: {[input.name for input in onnx_model.graph.input]}")
    print(f"è¾“å‡ºèŠ‚ç‚¹: {[output.name for output in onnx_model.graph.output]}")
    
    # æµ‹è¯•ONNX Runtimeæ¨ç†
    print("\næµ‹è¯•ONNX Runtimeæ¨ç†...")
    ort_session = onnxruntime.InferenceSession(onnx_path)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_input = dummy_input.numpy()
    
    # PyTorchæ¨ç†
    print("æ‰§è¡ŒPyTorchæ¨ç†...")
    with torch.no_grad():
        pytorch_output = model(dummy_input)
    
    # ONNX Runtimeæ¨ç†
    print("æ‰§è¡ŒONNX Runtimeæ¨ç†...")
    ort_inputs = {ort_session.get_inputs()[0].name: test_input}
    ort_output = ort_session.run(None, ort_inputs)
    
    # æ¯”è¾ƒç»“æœ
    print("æ¯”è¾ƒæ¨ç†ç»“æœ...")
    try:
        np.testing.assert_allclose(
            pytorch_output.numpy(), 
            ort_output[0], 
            rtol=1e-03, 
            atol=1e-05
        )
        print("âœ“ PyTorchå’ŒONNX Runtimeæ¨ç†ç»“æœä¸€è‡´")
    except AssertionError as e:
        print(f"âœ— æ¨ç†ç»“æœä¸ä¸€è‡´: {e}")
        return None
    
    # ä½¿ç”¨çœŸå®MNISTæ•°æ®æµ‹è¯•
    print("\nä½¿ç”¨çœŸå®MNISTæ•°æ®æµ‹è¯•...")
    test_with_real_data(model, ort_session)
    
    print(f"\nâœ“ ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸ: {onnx_path}")
    return onnx_path

def test_with_real_data(pytorch_model, onnx_session):
    """ä½¿ç”¨çœŸå®MNISTæ•°æ®æµ‹è¯•ä¸¤ä¸ªæ¨¡å‹çš„ä¸€è‡´æ€§"""
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    test_dataset = torchvision.datasets.MNIST(
        root='../data', train=False, download=False, transform=transform
    )
    
    # æµ‹è¯•5ä¸ªæ ·æœ¬
    print("æµ‹è¯•æ ·æœ¬:")
    for i in range(5):
        image, true_label = test_dataset[i]
        input_batch = image.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        
        # PyTorchæ¨ç†
        with torch.no_grad():
            pytorch_output = pytorch_model(input_batch)
            pytorch_pred = pytorch_output.argmax(dim=1).item()
            pytorch_prob = torch.exp(pytorch_output).max().item()
        
        # ONNXæ¨ç†
        ort_inputs = {onnx_session.get_inputs()[0].name: input_batch.numpy()}
        ort_output = onnx_session.run(None, ort_inputs)
        onnx_logits = ort_output[0]
        onnx_probs = np.exp(onnx_logits) / np.sum(np.exp(onnx_logits))
        onnx_pred = np.argmax(onnx_probs)
        onnx_prob = np.max(onnx_probs)
        
        # æ¯”è¾ƒç»“æœ
        match = "âœ“" if pytorch_pred == onnx_pred else "âœ—"
        print(f"  æ ·æœ¬{i}: çœŸå®={true_label}, PyTorch={pytorch_pred}({pytorch_prob:.3f}), "
              f"ONNX={onnx_pred}({onnx_prob:.3f}) {match}")



if __name__ == "__main__":
    onnx_path = export_to_onnx()
    
    if onnx_path:
        print(f"\nâœ… ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸ!")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {onnx_path}")
        print(f"ğŸ“Š å¯ä»¥ä½¿ç”¨Netronç­‰å·¥å…·å¤–éƒ¨æŸ¥çœ‹æ¨¡å‹ç»“æ„")
        print(f"\nğŸ‰ å¯¼å‡ºå®Œæˆï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥Pythonæ¨ç†æµ‹è¯•ï¼") 