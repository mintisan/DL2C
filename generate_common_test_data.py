#!/usr/bin/env python3
"""
ç”Ÿæˆä¸‰ç§è¯­è¨€é€šç”¨çš„æµ‹è¯•æ•°æ®
ç¡®ä¿Pythonã€C++ã€Cä½¿ç”¨å®Œå…¨ç›¸åŒçš„è¾“å…¥è¿›è¡Œå¯¹æ¯”
"""

import numpy as np
import torchvision
import torchvision.transforms as transforms
import json
import os
from pathlib import Path

def generate_common_test_data(num_samples=10):
    """ç”Ÿæˆé€šç”¨æµ‹è¯•æ•°æ®"""
    print("ğŸ”„ ç”Ÿæˆé€šç”¨æµ‹è¯•æ•°æ®...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
    test_data_dir = Path("./test_data")
    test_data_dir.mkdir(exist_ok=True)
    
    # åŠ è½½MNISTæµ‹è¯•æ•°æ®é›†
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    
    try:
        test_dataset = torchvision.datasets.MNIST(
            root='./data', 
            train=False, 
            download=True, 
            transform=transform
        )
        print("âœ… MNISTæ•°æ®é›†åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ MNISTæ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return None
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_samples = []
    
    # é€‰æ‹©å›ºå®šçš„æ ·æœ¬ç´¢å¼•ï¼Œç¡®ä¿ç»“æœå¯é‡ç°
    np.random.seed(42)  # å›ºå®šéšæœºç§å­
    sample_indices = np.random.choice(len(test_dataset), num_samples, replace=False)
    
    for i, idx in enumerate(sample_indices):
        image, label = test_dataset[idx]
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        image_np = image.squeeze().numpy()  # ç§»é™¤batchç»´åº¦ï¼Œå¾—åˆ°[28, 28]
        
        # ä¿å­˜åŸå§‹æ•°æ®ï¼ˆ0-1èŒƒå›´ï¼‰
        sample_data = {
            'sample_id': i,
            'true_label': int(label),
            'image_shape': [28, 28],
            'pixel_values': image_np.flatten().tolist(),  # å±•å¹³ä¸ºä¸€ç»´æ•°ç»„ä¾¿äºå­˜å‚¨
            'mnist_index': int(idx)
        }
        
        test_samples.append(sample_data)
        
        # åŒæ—¶ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ä¾›C/C++ä½¿ç”¨
        binary_file = test_data_dir / f"sample_{i:02d}.bin"
        image_np.astype(np.float32).tofile(binary_file)
        
        print(f"æ ·æœ¬ {i}: æ ‡ç­¾={label}, MNISTç´¢å¼•={idx}, ä¿å­˜åˆ°={binary_file}")
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata = {
        'num_samples': num_samples,
        'image_shape': [28, 28],
        'data_type': 'float32',
        'pixel_range': [0.0, 1.0],
        'description': 'MNISTæµ‹è¯•æ ·æœ¬ï¼Œç”¨äºä¸‰ç§è¯­è¨€æ¨ç†å¯¹æ¯”',
        'samples': test_samples
    }
    
    metadata_file = test_data_dir / "metadata.json"
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ç”Ÿæˆäº† {num_samples} ä¸ªæµ‹è¯•æ ·æœ¬")
    print(f"ğŸ“ æ•°æ®ä¿å­˜åœ¨: {test_data_dir}")
    print(f"ğŸ“„ å…ƒæ•°æ®æ–‡ä»¶: {metadata_file}")
    
    return metadata

def verify_test_data():
    """éªŒè¯ç”Ÿæˆçš„æµ‹è¯•æ•°æ®"""
    print("\nğŸ” éªŒè¯æµ‹è¯•æ•°æ®...")
    
    test_data_dir = Path("./test_data")
    metadata_file = test_data_dir / "metadata.json"
    
    if not metadata_file.exists():
        print("âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    print(f"æµ‹è¯•æ ·æœ¬æ•°é‡: {metadata['num_samples']}")
    print(f"å›¾åƒå°ºå¯¸: {metadata['image_shape']}")
    print(f"æ•°æ®ç±»å‹: {metadata['data_type']}")
    
    # éªŒè¯äºŒè¿›åˆ¶æ–‡ä»¶
    for i in range(metadata['num_samples']):
        binary_file = test_data_dir / f"sample_{i:02d}.bin"
        if binary_file.exists():
            # è¯»å–å¹¶éªŒè¯
            image_data = np.fromfile(binary_file, dtype=np.float32)
            expected_size = metadata['image_shape'][0] * metadata['image_shape'][1]
            
            if len(image_data) == expected_size:
                print(f"âœ… æ ·æœ¬ {i}: {binary_file.name} éªŒè¯é€šè¿‡")
            else:
                print(f"âŒ æ ·æœ¬ {i}: å¤§å°ä¸åŒ¹é…ï¼ŒæœŸæœ›={expected_size}, å®é™…={len(image_data)}")
        else:
            print(f"âŒ æ ·æœ¬ {i}: {binary_file} ä¸å­˜åœ¨")
    
    return True

if __name__ == "__main__":
    print("ğŸ¯ ç”Ÿæˆä¸‰ç§è¯­è¨€é€šç”¨æµ‹è¯•æ•°æ®")
    print("=" * 50)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    metadata = generate_common_test_data(num_samples=10)
    
    if metadata:
        # éªŒè¯æµ‹è¯•æ•°æ®
        verify_test_data()
        
        print("\nğŸ‰ æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆï¼")
        print("ç°åœ¨å¯ä»¥ä¿®æ”¹ä¸‰ç§è¯­è¨€çš„æ¨ç†ä»£ç æ¥ä½¿ç”¨ç›¸åŒçš„æ•°æ®")
    else:
        print("âŒ æµ‹è¯•æ•°æ®ç”Ÿæˆå¤±è´¥") 