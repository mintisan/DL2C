#!/usr/bin/env python3
"""
MNISTåŸå§‹æ•°æ®åŠ è½½å™¨
ç›´æ¥è¯»å–MNISTåŸå§‹æ ¼å¼æ•°æ®ï¼Œä¸ºä¸‰ç§è¯­è¨€æä¾›ç»Ÿä¸€çš„æµ‹è¯•æ•°æ®
"""

import struct
import numpy as np
import json
import os
from pathlib import Path

class MNISTDataLoader:
    """MNISTæ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, data_dir="./data/MNIST/raw"):
        self.data_dir = Path(data_dir)
        
    def load_images(self, filename):
        """åŠ è½½MNISTå›¾åƒæ–‡ä»¶"""
        filepath = self.data_dir / filename
        
        with open(filepath, 'rb') as f:
            # è¯»å–æ–‡ä»¶å¤´
            magic, num_images, rows, cols = struct.unpack('>IIII', f.read(16))
            
            if magic != 2051:
                raise ValueError(f"Invalid magic number: {magic}")
            
            print(f"åŠ è½½å›¾åƒ: {num_images} å¼ ï¼Œå°ºå¯¸: {rows}x{cols}")
            
            # è¯»å–å›¾åƒæ•°æ®
            images = np.frombuffer(f.read(), dtype=np.uint8)
            images = images.reshape(num_images, rows, cols)
            
            # å½’ä¸€åŒ–åˆ° [0, 1]
            images = images.astype(np.float32) / 255.0
            
            return images
    
    def load_labels(self, filename):
        """åŠ è½½MNISTæ ‡ç­¾æ–‡ä»¶"""
        filepath = self.data_dir / filename
        
        with open(filepath, 'rb') as f:
            # è¯»å–æ–‡ä»¶å¤´
            magic, num_labels = struct.unpack('>II', f.read(8))
            
            if magic != 2049:
                raise ValueError(f"Invalid magic number: {magic}")
            
            print(f"åŠ è½½æ ‡ç­¾: {num_labels} ä¸ª")
            
            # è¯»å–æ ‡ç­¾æ•°æ®
            labels = np.frombuffer(f.read(), dtype=np.uint8)
            
            return labels
    
    def create_test_subset(self, num_samples=100, random_seed=42):
        """åˆ›å»ºæµ‹è¯•å­é›†ï¼Œç¡®ä¿ç»“æœå¯é‡ç°"""
        print(f"ğŸ”„ åˆ›å»ºåŒ…å« {num_samples} ä¸ªæ ·æœ¬çš„æµ‹è¯•å­é›†...")
        
        # åŠ è½½å®Œæ•´çš„æµ‹è¯•æ•°æ®
        test_images = self.load_images("t10k-images-idx3-ubyte")
        test_labels = self.load_labels("t10k-labels-idx1-ubyte")
        
        # ä½¿ç”¨å›ºå®šç§å­é€‰æ‹©æ ·æœ¬
        np.random.seed(random_seed)
        indices = np.random.choice(len(test_images), num_samples, replace=False)
        indices = np.sort(indices)  # æ’åºä»¥ä¿è¯ä¸€è‡´æ€§
        
        selected_images = test_images[indices]
        selected_labels = test_labels[indices]
        
        print(f"âœ… é€‰æ‹©äº† {len(selected_images)} ä¸ªæ ·æœ¬")
        print(f"æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(selected_labels)}")
        
        return selected_images, selected_labels, indices
    
    def save_for_inference(self, images, labels, indices, output_dir="./test_data_mnist"):
        """ä¿å­˜æ•°æ®ä¾›ä¸‰ç§è¯­è¨€æ¨ç†ä½¿ç”¨"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ’¾ ä¿å­˜æ•°æ®åˆ°: {output_dir}")
        
        # ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ä¾›C/C++ä½¿ç”¨
        for i, (image, label, orig_idx) in enumerate(zip(images, labels, indices)):
            # ä¿å­˜å›¾åƒæ•°æ®
            binary_file = output_dir / f"image_{i:03d}.bin"
            image.astype(np.float32).tofile(binary_file)
            
            print(f"æ ·æœ¬ {i:3d}: æ ‡ç­¾={label}, åŸå§‹ç´¢å¼•={orig_idx}, æ–‡ä»¶={binary_file.name}")
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'num_samples': len(images),
            'image_shape': [28, 28],
            'data_type': 'float32',
            'pixel_range': [0.0, 1.0],
            'description': 'MNISTæµ‹è¯•å­é›†ï¼Œç”¨äºä¸‰ç§è¯­è¨€æ¨ç†å¯¹æ¯”',
            'random_seed': 42,
            'samples': []
        }
        
        for i, (label, orig_idx) in enumerate(zip(labels, indices)):
            metadata['samples'].append({
                'sample_id': i,
                'true_label': int(label),
                'original_mnist_index': int(orig_idx),
                'image_file': f"image_{i:03d}.bin"
            })
        
        metadata_file = output_dir / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ä¸ºNPZæ–‡ä»¶ä¾›Pythonä½¿ç”¨
        npz_file = output_dir / "mnist_test_subset.npz"
        np.savez(npz_file, 
                images=images, 
                labels=labels, 
                indices=indices)
        
        print(f"âœ… ä¿å­˜å®Œæˆ:")
        print(f"  - äºŒè¿›åˆ¶æ–‡ä»¶: {len(images)} ä¸ª *.bin æ–‡ä»¶")
        print(f"  - å…ƒæ•°æ®: {metadata_file}")
        print(f"  - Pythonæ•°æ®: {npz_file}")
        
        return metadata
    
    def verify_data_consistency(self, output_dir="./test_data_mnist"):
        """éªŒè¯ä¿å­˜çš„æ•°æ®ä¸€è‡´æ€§"""
        print("\nğŸ” éªŒè¯æ•°æ®ä¸€è‡´æ€§...")
        
        output_dir = Path(output_dir)
        
        # åŠ è½½å…ƒæ•°æ®
        metadata_file = output_dir / "metadata.json"
        with open(metadata_file, 'r') as f:
            metadata = json.load(f)
        
        # åŠ è½½NPZæ–‡ä»¶
        npz_file = output_dir / "mnist_test_subset.npz"
        npz_data = np.load(npz_file)
        
        print(f"å…ƒæ•°æ®æ ·æœ¬æ•°: {metadata['num_samples']}")
        print(f"NPZæ•°æ®å½¢çŠ¶: {npz_data['images'].shape}")
        
        # éªŒè¯äºŒè¿›åˆ¶æ–‡ä»¶
        success_count = 0
        for i in range(metadata['num_samples']):
            binary_file = output_dir / f"image_{i:03d}.bin"
            if binary_file.exists():
                # è¯»å–äºŒè¿›åˆ¶æ•°æ®
                bin_data = np.fromfile(binary_file, dtype=np.float32).reshape(28, 28)
                npz_data_sample = npz_data['images'][i]
                
                # æ¯”è¾ƒæ•°æ®
                if np.allclose(bin_data, npz_data_sample):
                    success_count += 1
                else:
                    print(f"âŒ æ ·æœ¬ {i} æ•°æ®ä¸ä¸€è‡´")
        
        print(f"âœ… éªŒè¯å®Œæˆ: {success_count}/{metadata['num_samples']} ä¸ªæ–‡ä»¶ä¸€è‡´")
        
        return success_count == metadata['num_samples']

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ MNISTåŸå§‹æ•°æ®åŠ è½½å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = "./data/MNIST/raw"
    if not os.path.exists(data_dir):
        print(f"âŒ MNISTæ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("è¯·ç¡®ä¿å·²ä¸‹è½½MNISTæ•°æ®é›†")
        return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    loader = MNISTDataLoader(data_dir)
    
    # åˆ›å»ºæµ‹è¯•å­é›†ï¼ˆå¯ä»¥è°ƒæ•´æ ·æœ¬æ•°é‡ï¼‰
    num_samples = 100  # å¯ä»¥æ”¹ä¸ºæ›´å¤§çš„æ•°å­—ï¼Œæ¯”å¦‚1000æˆ–10000
    images, labels, indices = loader.create_test_subset(num_samples=num_samples)
    
    # ä¿å­˜æ•°æ®
    metadata = loader.save_for_inference(images, labels, indices)
    
    # éªŒè¯æ•°æ®
    if loader.verify_data_consistency():
        print("\nğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆï¼")
        print("ç°åœ¨å¯ä»¥ä½¿ç”¨åŸå§‹MNISTæ•°æ®è¿›è¡Œä¸‰ç§è¯­è¨€çš„æ¨ç†å¯¹æ¯”")
        print(f"æµ‹è¯•æ ·æœ¬æ•°: {num_samples}")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  1. Python: ç›´æ¥åŠ è½½ mnist_test_subset.npz")
        print("  2. C/C++: è¯»å– image_*.bin æ–‡ä»¶å’Œ metadata.json")
    else:
        print("âŒ æ•°æ®éªŒè¯å¤±è´¥")

if __name__ == "__main__":
    main() 