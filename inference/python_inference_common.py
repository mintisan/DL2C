#!/usr/bin/env python3
"""
Python ONNXæ¨ç† - ä½¿ç”¨å…±åŒæµ‹è¯•æ•°æ®
ä¸C/C++ç‰ˆæœ¬ä½¿ç”¨å®Œå…¨ç›¸åŒçš„è¾“å…¥æ•°æ®è¿›è¡Œå¯¹æ¯”
"""

import onnxruntime as ort
import numpy as np
import json
import time
import os
from pathlib import Path

class PythonONNXInferenceCommon:
    """Python ONNXæ¨ç†ç±» - ä½¿ç”¨å…±åŒæµ‹è¯•æ•°æ®"""
    
    def __init__(self, model_path):
        """åˆå§‹åŒ–ONNXæ¨ç†å¼•æ“"""
        print(f"åŠ è½½ONNXæ¨¡å‹: {model_path}")
        
        # åˆ›å»ºONNX Runtimeä¼šè¯
        providers = ['CPUExecutionProvider']
        self.session = ort.InferenceSession(model_path, providers=providers)
        
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name
        
        print(f"âœ… Python ONNX Runtimeåˆå§‹åŒ–æˆåŠŸ")
        print(f"è¾“å…¥åç§°: {self.input_name}")
        print(f"è¾“å‡ºåç§°: {self.output_name}")
        
    def preprocess(self, image_data):
        """é¢„å¤„ç†å›¾åƒæ•°æ®"""
        # è¾“å…¥æ•°æ®å·²ç»æ˜¯[28, 28]çš„float32æ•°ç»„ï¼ŒèŒƒå›´[0,1]
        # éœ€è¦æ ‡å‡†åŒ–å¹¶è°ƒæ•´å½¢çŠ¶
        
        # æ ‡å‡†åŒ– (MNISTæ ‡å‡†åŒ–å‚æ•°)
        mean = 0.1307
        std = 0.3081
        normalized = (image_data - mean) / std
        
        # è°ƒæ•´å½¢çŠ¶ä¸º [1, 1, 28, 28]
        input_data = normalized.reshape(1, 1, 28, 28).astype(np.float32)
        
        return input_data
    
    def postprocess(self, output):
        """åå¤„ç†è¾“å‡ºç»“æœ"""
        # è·å–ONNXè¾“å‡º
        logits = output[0][0]  # ä» [1, 10] å˜ä¸º [10]
        
        # åº”ç”¨softmaxè·å¾—æ¦‚ç‡åˆ†å¸ƒ
        exp_logits = np.exp(logits - np.max(logits))
        probabilities = exp_logits / np.sum(exp_logits)
        
        # è·å–é¢„æµ‹ç±»åˆ«å’Œç½®ä¿¡åº¦
        predicted_class = np.argmax(probabilities)
        confidence = probabilities[predicted_class]
        
        return {
            'predicted_class': int(predicted_class),
            'confidence': float(confidence),
            'probabilities': probabilities.tolist(),
            'raw_logits': logits.tolist()
        }
    
    def inference(self, image_data):
        """æ‰§è¡Œæ¨ç†"""
        start_time = time.time()
        
        # é¢„å¤„ç†
        processed_input = self.preprocess(image_data)
        
        # è¿è¡Œæ¨ç†
        ort_inputs = {self.input_name: processed_input}
        ort_outputs = self.session.run([self.output_name], ort_inputs)
        
        end_time = time.time()
        inference_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        # åå¤„ç†
        result = self.postprocess(ort_outputs)
        result['inference_time_ms'] = inference_time
        
        return result

def load_common_test_data():
    """åŠ è½½å…±åŒçš„æµ‹è¯•æ•°æ®"""
    test_data_dir = Path("../test_data")
    metadata_file = test_data_dir / "metadata.json"
    
    if not metadata_file.exists():
        print("âŒ æ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ generate_common_test_data.py")
        return None, None
    
    # åŠ è½½å…ƒæ•°æ®
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    print(f"ğŸ” åŠ è½½ {metadata['num_samples']} ä¸ªæµ‹è¯•æ ·æœ¬")
    
    # åŠ è½½äºŒè¿›åˆ¶æ•°æ®
    test_samples = []
    true_labels = []
    
    for i in range(metadata['num_samples']):
        # è¯»å–äºŒè¿›åˆ¶æ•°æ®
        binary_file = test_data_dir / f"sample_{i:02d}.bin"
        image_data = np.fromfile(binary_file, dtype=np.float32)
        image_data = image_data.reshape(28, 28)
        
        test_samples.append(image_data)
        true_labels.append(metadata['samples'][i]['true_label'])
        
        print(f"æ ·æœ¬ {i}: çœŸå®æ ‡ç­¾={metadata['samples'][i]['true_label']}")
    
    return test_samples, true_labels

def test_python_inference_common():
    """ä½¿ç”¨å…±åŒæµ‹è¯•æ•°æ®è¿›è¡ŒPythonæ¨ç†æµ‹è¯•"""
    print("=== Python ONNXæ¨ç†æµ‹è¯• (å…±åŒæ•°æ®) ===")
    
    # åŠ è½½æ¨¡å‹
    model_path = '../models/mnist_model.onnx'
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None
    
    inference_engine = PythonONNXInferenceCommon(model_path)
    
    # åŠ è½½å…±åŒæµ‹è¯•æ•°æ®
    test_samples, true_labels = load_common_test_data()
    if test_samples is None:
        return None
    
    print(f"\nå¼€å§‹æ¨ç† {len(test_samples)} ä¸ªæ ·æœ¬...")
    
    # æ‰§è¡Œæ¨ç†
    results = []
    correct_predictions = 0
    total_time = 0
    
    for i, (image_data, true_label) in enumerate(zip(test_samples, true_labels)):
        # æ‰§è¡Œæ¨ç†
        result = inference_engine.inference(image_data)
        
        # æ£€æŸ¥å‡†ç¡®æ€§
        is_correct = result['predicted_class'] == true_label
        if is_correct:
            correct_predictions += 1
        
        # è®°å½•ç»“æœ
        sample_result = {
            'sample_id': i,
            'true_label': true_label,
            'predicted_class': result['predicted_class'],
            'confidence': result['confidence'],
            'inference_time_ms': result['inference_time_ms'],
            'is_correct': is_correct,
            'probabilities': result['probabilities']
        }
        
        results.append(sample_result)
        total_time += result['inference_time_ms']
        
        print(f"æ ·æœ¬ {i:2d}: çœŸå®={true_label}, é¢„æµ‹={result['predicted_class']}, "
              f"ç½®ä¿¡åº¦={result['confidence']:.4f}, æ—¶é—´={result['inference_time_ms']:.2f}ms, "
              f"{'âœ“' if is_correct else 'âœ—'}")
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    accuracy = correct_predictions / len(results)
    avg_time = total_time / len(results)
    std_time = np.std([r['inference_time_ms'] for r in results])
    
    print(f"\n=== æ¨ç†ç»“æœç»Ÿè®¡ ===")
    print(f"æ€»æ ·æœ¬æ•°: {len(results)}")
    print(f"æ­£ç¡®é¢„æµ‹: {correct_predictions}")
    print(f"å‡†ç¡®ç‡: {accuracy:.2%}")
    print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f} ms")
    print(f"æ ‡å‡†å·®: {std_time:.2f} ms")
    print(f"æ¨ç†é€Ÿåº¦: {1000/avg_time:.1f} FPS")
    
    # ä¿å­˜ç»“æœ
    summary_result = {
        'platform': 'Python',
        'framework': 'ONNX Runtime Python API',
        'test_type': 'common_data',
        'results': results,
        'summary': {
            'accuracy': accuracy,
            'average_inference_time_ms': avg_time,
            'std_inference_time_ms': std_time,
            'fps': 1000/avg_time,
            'total_samples': len(results),
            'correct_predictions': correct_predictions
        }
    }
    
    # ç¡®ä¿resultsç›®å½•å­˜åœ¨
    os.makedirs('../results', exist_ok=True)
    
    with open('../results/python_inference_common_results.json', 'w', encoding='utf-8') as f:
        json.dump(summary_result, f, indent=2, ensure_ascii=False)
    
    print("ç»“æœå·²ä¿å­˜åˆ°: ../results/python_inference_common_results.json")
    
    return summary_result

if __name__ == "__main__":
    results = test_python_inference_common()
    
    if results:
        print("\nâœ… Pythonæ¨ç†æµ‹è¯•å®Œæˆ")
        print("ç°åœ¨å¯ä»¥è¿è¡ŒC/C++æ¨ç†æµ‹è¯•è¿›è¡Œå¯¹æ¯”")
    else:
        print("âŒ Pythonæ¨ç†æµ‹è¯•å¤±è´¥") 