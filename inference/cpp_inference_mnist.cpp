// C++ ONNXæ¨ç† - ä½¿ç”¨çœŸå®MNISTæµ‹è¯•æ•°æ®
#include <iostream>
#include <vector>
#include <chrono>
#include <cmath>
#include <algorithm>
#include <fstream>
#include <iomanip>
#include <stdexcept>
#include <string>

// ä½¿ç”¨C APIé¿å…ä¾èµ–é—®é¢˜
extern "C" {
#include "onnxruntime_c_api.h"
}

class CppONNXInferenceMNIST {
private:
    const OrtApi* ort_api;
    OrtEnv* env;
    OrtSession* session;
    OrtMemoryInfo* memory_info;
    
public:
    struct InferenceResult {
        int sample_id;
        int original_mnist_index;
        int true_label;
        int predicted_class;
        float confidence;
        std::vector<float> probabilities;
        double inference_time_ms;
        bool is_correct;
    };
    
    CppONNXInferenceMNIST(const std::string& model_path) {
        std::cout << "=== C++ ONNXæ¨ç†æµ‹è¯• (çœŸå®MNISTæ•°æ®) ===" << std::endl;
        std::cout << "åˆå§‹åŒ–ONNX Runtime C API..." << std::endl;
        
        // è·å–API
        ort_api = OrtGetApiBase()->GetApi(ORT_API_VERSION);
        
        // åˆ›å»ºç¯å¢ƒ
        OrtStatus* status = ort_api->CreateEnv(ORT_LOGGING_LEVEL_WARNING, "CppONNXInferenceMNIST", &env);
        if (status != nullptr) {
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("åˆ›å»ºç¯å¢ƒå¤±è´¥");
        }
        
        // åˆ›å»ºä¼šè¯é€‰é¡¹
        OrtSessionOptions* session_options;
        status = ort_api->CreateSessionOptions(&session_options);
        if (status != nullptr) {
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("åˆ›å»ºä¼šè¯é€‰é¡¹å¤±è´¥");
        }
        
        // åˆ›å»ºä¼šè¯
        status = ort_api->CreateSession(env, model_path.c_str(), session_options, &session);
        if (status != nullptr) {
            ort_api->ReleaseSessionOptions(session_options);
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("åŠ è½½æ¨¡å‹å¤±è´¥: " + model_path);
        }
        
        // åˆ›å»ºå†…å­˜ä¿¡æ¯
        status = ort_api->CreateCpuMemoryInfo(OrtArenaAllocator, OrtMemTypeDefault, &memory_info);
        if (status != nullptr) {
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("åˆ›å»ºå†…å­˜ä¿¡æ¯å¤±è´¥");
        }
        
        ort_api->ReleaseSessionOptions(session_options);
        std::cout << "âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: " << model_path << std::endl;
    }
    
    ~CppONNXInferenceMNIST() {
        if (memory_info) ort_api->ReleaseMemoryInfo(memory_info);
        if (session) ort_api->ReleaseSession(session);
        if (env) ort_api->ReleaseEnv(env);
    }
    
    std::vector<float> preprocess(const std::vector<float>& raw_data) {
        std::vector<float> processed = raw_data;
        
        // MNISTæ ‡å‡†åŒ–
        const float mean = 0.1307f;
        const float std = 0.3081f;
        
        for (auto& pixel : processed) {
            pixel = (pixel - mean) / std;
        }
        
        return processed;
    }
    
    std::vector<float> softmax(const std::vector<float>& logits) {
        std::vector<float> probabilities(logits.size());
        float max_logit = *std::max_element(logits.begin(), logits.end());
        
        float sum = 0.0f;
        for (size_t i = 0; i < logits.size(); ++i) {
            probabilities[i] = std::exp(logits[i] - max_logit);
            sum += probabilities[i];
        }
        
        for (auto& prob : probabilities) {
            prob /= sum;
        }
        
        return probabilities;
    }
    
    InferenceResult inference(int sample_id, int original_idx, int true_label, const std::vector<float>& input_data) {
        auto start = std::chrono::high_resolution_clock::now();
        
        // é¢„å¤„ç†
        auto processed_data = preprocess(input_data);
        
        // åˆ›å»ºè¾“å…¥tensor
        int64_t input_shape[] = {1, 1, 28, 28};
        OrtValue* input_tensor = nullptr;
        
        OrtStatus* status = ort_api->CreateTensorWithDataAsOrtValue(
            memory_info,
            processed_data.data(),
            processed_data.size() * sizeof(float),
            input_shape,
            4,
            ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT,
            &input_tensor
        );
        
        if (status != nullptr) {
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("åˆ›å»ºè¾“å…¥tensorå¤±è´¥");
        }
        
        // è®¾ç½®è¾“å…¥è¾“å‡ºåç§°
        const char* input_names[] = {"input"};
        const char* output_names[] = {"output"};
        
        // è¿è¡Œæ¨ç†
        OrtValue* output_tensor = nullptr;
        status = ort_api->Run(
            session,
            nullptr,
            input_names,
            (const OrtValue* const*)&input_tensor,
            1,
            output_names,
            1,
            &output_tensor
        );
        
        if (status != nullptr) {
            ort_api->ReleaseValue(input_tensor);
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("æ¨ç†æ‰§è¡Œå¤±è´¥");
        }
        
        // è·å–è¾“å‡ºæ•°æ®
        float* output_data;
        status = ort_api->GetTensorMutableData(output_tensor, (void**)&output_data);
        if (status != nullptr) {
            ort_api->ReleaseValue(input_tensor);
            ort_api->ReleaseValue(output_tensor);
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("è·å–è¾“å‡ºæ•°æ®å¤±è´¥");
        }
        
        // è·å–è¾“å‡ºå½¢çŠ¶
        OrtTensorTypeAndShapeInfo* output_info;
        status = ort_api->GetTensorTypeAndShape(output_tensor, &output_info);
        if (status != nullptr) {
            ort_api->ReleaseValue(input_tensor);
            ort_api->ReleaseValue(output_tensor);
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("è·å–è¾“å‡ºå½¢çŠ¶å¤±è´¥");
        }
        
        size_t output_count;
        status = ort_api->GetTensorShapeElementCount(output_info, &output_count);
        if (status != nullptr) {
            ort_api->ReleaseValue(input_tensor);
            ort_api->ReleaseValue(output_tensor);
            ort_api->ReleaseTensorTypeAndShapeInfo(output_info);
            ort_api->ReleaseStatus(status);
            throw std::runtime_error("è·å–è¾“å‡ºå…ƒç´ æ•°é‡å¤±è´¥");
        }
        
        // å¤åˆ¶è¾“å‡ºæ•°æ®
        std::vector<float> logits(output_data, output_data + output_count);
        std::vector<float> probabilities = softmax(logits);
        
        // æ‰¾åˆ°é¢„æµ‹ç±»åˆ«
        auto max_it = std::max_element(probabilities.begin(), probabilities.end());
        int predicted_class = std::distance(probabilities.begin(), max_it);
        float confidence = *max_it;
        
        auto end = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
        
        // æ¸…ç†èµ„æº
        ort_api->ReleaseValue(input_tensor);
        ort_api->ReleaseValue(output_tensor);
        ort_api->ReleaseTensorTypeAndShapeInfo(output_info);
        
        InferenceResult result;
        result.sample_id = sample_id;
        result.original_mnist_index = original_idx;
        result.true_label = true_label;
        result.predicted_class = predicted_class;
        result.confidence = confidence;
        result.probabilities = probabilities;
        result.inference_time_ms = duration.count() / 1000.0;
        result.is_correct = (predicted_class == true_label);
        
        return result;
    }
};

// ç»“æ„ä½“ç”¨äºå­˜å‚¨MNISTæµ‹è¯•æ•°æ®
struct MNISTTestData {
    std::vector<std::vector<float>> images;
    std::vector<int> labels;
    std::vector<int> original_indices;
};

// è¯»å–MNISTæµ‹è¯•æ•°æ®
MNISTTestData load_mnist_test_data() {
    std::cout << "ğŸ” åŠ è½½MNISTæµ‹è¯•æ•°æ®..." << std::endl;
    
    MNISTTestData data;
    
    // è¯»å–å…ƒæ•°æ®ä»¥è·å–æ ‡ç­¾å’Œç´¢å¼•ä¿¡æ¯
    std::ifstream metadata_file("../../test_data_mnist/metadata.json");
    if (!metadata_file.is_open()) {
        throw std::runtime_error("âŒ æ— æ³•æ‰“å¼€å…ƒæ•°æ®æ–‡ä»¶");
    }
    
    // ç®€å•è§£æJSONè·å–ä¿¡æ¯
    std::string line;
    std::vector<int> labels;
    std::vector<int> indices;
    int num_samples = 0;
    
    while (std::getline(metadata_file, line)) {
        // è·å–æ ·æœ¬æ•°é‡
        size_t pos = line.find("\"num_samples\":");
        if (pos != std::string::npos) {
            pos += 14;
            while (pos < line.length() && (line[pos] == ' ' || line[pos] == '"')) pos++;
            size_t end_pos = line.find(',', pos);
            if (end_pos == std::string::npos) end_pos = line.find('}', pos);
            num_samples = std::stoi(line.substr(pos, end_pos - pos));
        }
        
        // è·å–æ ‡ç­¾
        pos = line.find("\"true_label\":");
        if (pos != std::string::npos) {
            pos += 13;
            while (pos < line.length() && (line[pos] == ' ' || line[pos] == '"')) pos++;
            size_t end_pos = line.find(',', pos);
            int label = std::stoi(line.substr(pos, end_pos - pos));
            labels.push_back(label);
        }
        
        // è·å–åŸå§‹ç´¢å¼•
        pos = line.find("\"original_mnist_index\":");
        if (pos != std::string::npos) {
            pos += 23;
            while (pos < line.length() && (line[pos] == ' ' || line[pos] == '"')) pos++;
            size_t end_pos = line.find(',', pos);
            int index = std::stoi(line.substr(pos, end_pos - pos));
            indices.push_back(index);
        }
    }
    metadata_file.close();
    
    std::cout << "æ ·æœ¬æ•°é‡: " << num_samples << std::endl;
    std::cout << "è§£æåˆ°çš„æ ‡ç­¾æ•°: " << labels.size() << std::endl;
    
    // è¯»å–å›¾åƒæ–‡ä»¶
    for (int i = 0; i < num_samples; ++i) {
        std::string filename = std::string("../../test_data_mnist/image_") + 
                              (i < 100 ? (i < 10 ? "00" : "0") : "") + std::to_string(i) + ".bin";
        
        std::ifstream file(filename, std::ios::binary);
        if (!file.is_open()) {
            std::cout << "âŒ æ— æ³•æ‰“å¼€æ–‡ä»¶: " << filename << std::endl;
            continue;
        }
        
        // è¯»å–28*28ä¸ªfloat32å€¼
        std::vector<float> image_data(28 * 28);
        file.read(reinterpret_cast<char*>(image_data.data()), 28 * 28 * sizeof(float));
        file.close();
        
        data.images.push_back(image_data);
        data.labels.push_back(labels[i]);
        data.original_indices.push_back(indices[i]);
    }
    
    std::cout << "âœ… åŠ è½½äº† " << data.images.size() << " ä¸ªæµ‹è¯•æ ·æœ¬" << std::endl;
    
    // æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒ
    std::vector<int> label_count(10, 0);
    for (int label : data.labels) {
        label_count[label]++;
    }
    std::cout << "æ ‡ç­¾åˆ†å¸ƒ: [";
    for (size_t i = 0; i < label_count.size(); ++i) {
        std::cout << label_count[i];
        if (i < label_count.size() - 1) std::cout << " ";
    }
    std::cout << "]" << std::endl;
    
    return data;
}

// ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
void save_results_to_json(const std::vector<CppONNXInferenceMNIST::InferenceResult>& results, 
                         double avg_time, double accuracy, int wrong_count) {
    // åˆ›å»ºç›®å½•
    system("mkdir -p ../../results 2>/dev/null || mkdir ..\\..\\results 2>nul || true");
    
    std::ofstream file("../../results/cpp_inference_mnist_results.json");
    if (!file.is_open()) {
        std::cout << "æ— æ³•åˆ›å»ºç»“æœæ–‡ä»¶" << std::endl;
        return;
    }
    
    file << "{\n";
    file << "  \"platform\": \"C++\",\n";
    file << "  \"framework\": \"ONNX Runtime C++ API\",\n";
    file << "  \"test_type\": \"real_mnist_data\",\n";
    file << "  \"data_source\": \"MNIST test set subset\",\n";
    file << "  \"summary\": {\n";
    file << "    \"accuracy\": " << std::fixed << std::setprecision(4) << accuracy << ",\n";
    file << "    \"average_inference_time_ms\": " << std::setprecision(2) << avg_time << ",\n";
    file << "    \"fps\": " << std::setprecision(1) << (1000.0 / avg_time) << ",\n";
    file << "    \"total_samples\": " << results.size() << ",\n";
    
    int correct = 0;
    for (const auto& r : results) {
        if (r.is_correct) correct++;
    }
    file << "    \"correct_predictions\": " << correct << ",\n";
    file << "    \"wrong_predictions\": " << wrong_count << "\n";
    file << "  },\n";
    file << "  \"results\": [\n";
    
    for (size_t i = 0; i < results.size(); ++i) {
        file << "    {\n";
        file << "      \"sample_id\": " << results[i].sample_id << ",\n";
        file << "      \"original_mnist_index\": " << results[i].original_mnist_index << ",\n";
        file << "      \"true_label\": " << results[i].true_label << ",\n";
        file << "      \"predicted_class\": " << results[i].predicted_class << ",\n";
        file << "      \"confidence\": " << std::setprecision(4) << results[i].confidence << ",\n";
        file << "      \"inference_time_ms\": " << std::setprecision(2) << results[i].inference_time_ms << ",\n";
        file << "      \"is_correct\": " << (results[i].is_correct ? "true" : "false") << "\n";
        file << "    }";
        if (i < results.size() - 1) file << ",";
        file << "\n";
    }
    
    file << "  ]\n";
    file << "}\n";
    file.close();
    
    std::cout << "ç»“æœå·²ä¿å­˜åˆ°: ../../results/cpp_inference_mnist_results.json" << std::endl;
}

int main() {
    try {
        // åˆå§‹åŒ–æ¨ç†å¼•æ“
        CppONNXInferenceMNIST inference_engine("../../models/mnist_model.onnx");
        
        // åŠ è½½æµ‹è¯•æ•°æ®
        auto test_data = load_mnist_test_data();
        
        if (test_data.images.empty()) {
            std::cout << "âŒ æ²¡æœ‰åŠ è½½åˆ°æµ‹è¯•æ•°æ®" << std::endl;
            return -1;
        }
        
        std::cout << "\nå¼€å§‹æ¨ç† " << test_data.images.size() << " ä¸ªæ ·æœ¬..." << std::endl;
        
        // æ‰§è¡Œæ¨ç†
        std::vector<CppONNXInferenceMNIST::InferenceResult> results;
        double total_time = 0.0;
        int correct_predictions = 0;
        
        for (size_t i = 0; i < test_data.images.size(); ++i) {
            auto result = inference_engine.inference(
                i, 
                test_data.original_indices[i], 
                test_data.labels[i], 
                test_data.images[i]
            );
            results.push_back(result);
            
            total_time += result.inference_time_ms;
            if (result.is_correct) {
                correct_predictions++;
            }
            
            // æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10ä¸ªæ ·æœ¬ï¼‰
            if ((i + 1) % 10 == 0) {
                double current_accuracy = (double)correct_predictions / (i + 1) * 100;
                std::cout << "å®Œæˆ " << std::setw(3) << (i+1) << "/" << test_data.images.size() 
                          << " æ ·æœ¬ï¼Œå½“å‰å‡†ç¡®ç‡: " << std::fixed << std::setprecision(1) 
                          << current_accuracy << "%" << std::endl;
            }
        }
        
        // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        double avg_time = total_time / test_data.images.size();
        double accuracy = static_cast<double>(correct_predictions) / test_data.images.size();
        int wrong_count = test_data.images.size() - correct_predictions;
        
        std::cout << "\n=== æ¨ç†ç»“æœç»Ÿè®¡ ===" << std::endl;
        std::cout << "æ€»æ ·æœ¬æ•°: " << test_data.images.size() << std::endl;
        std::cout << "æ­£ç¡®é¢„æµ‹: " << correct_predictions << std::endl;
        std::cout << "å‡†ç¡®ç‡: " << std::fixed << std::setprecision(2) << accuracy * 100 << "%" << std::endl;
        std::cout << "å¹³å‡æ¨ç†æ—¶é—´: " << std::setprecision(2) << avg_time << "ms" << std::endl;
        std::cout << "æ¨ç†é€Ÿåº¦: " << std::setprecision(1) << 1000.0 / avg_time << " FPS" << std::endl;
        
        // æ˜¾ç¤ºé”™è¯¯æ ·æœ¬
        if (wrong_count > 0) {
            std::cout << "\nâŒ é”™è¯¯é¢„æµ‹æ ·æœ¬ (" << wrong_count << " ä¸ª):" << std::endl;
            int shown = 0;
            for (const auto& result : results) {
                if (!result.is_correct && shown < 5) {
                    std::cout << "  æ ·æœ¬ " << std::setw(3) << result.sample_id 
                              << ": çœŸå®=" << result.true_label
                              << ", é¢„æµ‹=" << result.predicted_class
                              << ", ç½®ä¿¡åº¦=" << std::setprecision(3) << result.confidence << std::endl;
                    shown++;
                }
            }
            if (wrong_count > 5) {
                std::cout << "  ... è¿˜æœ‰ " << (wrong_count - 5) << " ä¸ªé”™è¯¯æ ·æœ¬" << std::endl;
            }
        }
        
        // ä¿å­˜ç»“æœ
        save_results_to_json(results, avg_time, accuracy, wrong_count);
        
        std::cout << "\nâœ… C++æ¨ç†æµ‹è¯•å®Œæˆï¼" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ é”™è¯¯: " << e.what() << std::endl;
        return -1;
    }
    
    return 0;
} 